{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import platform\n",
    "import os\n",
    "if platform.system() == 'Darwin':\n",
    "    DATA_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Thesis\"\n",
    "elif platform.system() == 'Linux':\n",
    "    DATA_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis\"\n",
    "\n",
    "current_wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda as device\n"
     ]
    }
   ],
   "source": [
    "def set_device():\n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            device = 'cuda'\n",
    "        elif torch.backends.mps.is_available():\n",
    "            device = 'mps'\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "    except:\n",
    "        if torch.cuda.is_available():\n",
    "            device = 'cuda'\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "    print(f\"Using {device} as device\")\n",
    "    return device\n",
    "\n",
    "device = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = f\"{DATA_PATH}/Zalando_Germany_Dataset/dresses/images/e4e_images/all/\"\n",
    "generated_path_00003 = f\"{DATA_PATH}/Generated_Images/e4e/00003_snapshot_920/\"\n",
    "generated_path_00005 = f\"{DATA_PATH}/Generated_Images/e4e/00005_snapshot_1200/\"\n",
    "generated_path_pti = f\"{DATA_PATH}/Generated_Images/PTI/\"\n",
    "generated_path_restyle = f\"{DATA_PATH}/Generated_Images/restyle/inference_results/4/\"\n",
    "\n",
    "\n",
    "scores_save_path_00003 = f\"{DATA_PATH}/Metrics/MSSSIM/e4e_00003_snapshot_920/msssim_scores_e4e_00003_snapshot_920.pkl\"\n",
    "scores_save_path_00005 = f\"{DATA_PATH}/Metrics/MSSSIM/e4e_00005_snapshot_1200/msssim_scores_e4e_00005_snapshot_1200.pkl\"\n",
    "scores_save_path_pti = f\"{DATA_PATH}/Metrics/MSSSIM/PTI/msssim_scores_pti.pkl\"\n",
    "scores_save_path_restyle = f\"{DATA_PATH}/Metrics/MSSSIM/Restyle/msssim_restyle_scores.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Datasets and Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedDataset(Dataset):\n",
    "\n",
    "    def __init__(self, real_path, generated_path, transform):\n",
    "        self.real_path = real_path\n",
    "        self.generated_path = generated_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pairs = []\n",
    "        self.real_images = glob(f\"{real_path}*.jpg\")\n",
    "        self.generate_images = glob(f\"{generated_path}*.jpg\")\n",
    "        for sku in os.listdir(generated_path):\n",
    "            real = [elem for elem in self.real_images if sku in elem][0]\n",
    "            generated= [elem for elem in self.generate_images if sku in elem][0]\n",
    "            self.pairs.append([real, generated])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        real, fake = self.pairs[index]\n",
    "        sku = real.split('/')[-1].split('.')[0]\n",
    "        img_real = Image.open(real).convert('RGB')\n",
    "        img_fake = Image.open(fake).convert('RGB')\n",
    "        if self.transform:\n",
    "            img_real = self.transform(img_real)\n",
    "            img_fake = self.transform(img_fake)\n",
    "        return img_real, img_fake, sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((256, 256)),\n",
    "\t\t\t\t\t\t\t\t\ttransforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\t\ttransforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "\t\t\t\t\t\t\t\t\t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ms_ssim import MSSSIM\n",
    "loss_fn = MSSSIM()\n",
    "def calculate_msssim_losses(generated_path, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        print(f'Calculating all MSSSIM-Losses for {save_path}')\n",
    "        # Create Dataset and Loader\n",
    "        print(\"\\tConstructing Dataset\")\n",
    "        ds = PairedDataset(real_path, generated_path, transform)\n",
    "        loader = DataLoader(ds, batch_size=1, shuffle = False)\n",
    "        # Calculate Losses\n",
    "        msssim_losses = {}\n",
    "        for real, fake, sku in tqdm(loader, desc = '\\tCalculating Losses'):\n",
    "            msssim_losses[sku[0]] = float(loss_fn(real.to(device), fake.to(device)))\n",
    "        \n",
    "        # Save Losses\n",
    "        with open(save_path, 'wb') as handle:\n",
    "            pickle.dump(msssim_losses, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    else:\n",
    "        print(f'MSSSIM-Losses already calculated for {generated_path}')\n",
    "        print('Loading pre-calculated losses')\n",
    "        with open(save_path, 'rb') as f:\n",
    "            msssim_losses = pickle.load(f)\n",
    "\n",
    "    return np.nanmean(list(msssim_losses.values()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calulate all MS-SSIM-Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSSIM-Losses already calculated for /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Generated_Images/e4e/00003_snapshot_920/\n",
      "Loading pre-calculated losses\n",
      "MSSSIM-Losses already calculated for /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Generated_Images/e4e/00005_snapshot_1200/\n",
      "Loading pre-calculated losses\n",
      "MSSSIM-Losses already calculated for /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Generated_Images/PTI/\n",
      "Loading pre-calculated losses\n",
      "MSSSIM-Losses already calculated for /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Generated_Images/restyle/inference_results/4/\n",
      "Loading pre-calculated losses\n"
     ]
    }
   ],
   "source": [
    "mean_msssim_losses = {}\n",
    "# e4e 00003_snapshot_920\n",
    "mean_msssim_losses['e4e_00003'] = calculate_msssim_losses(generated_path_00003, scores_save_path_00003)\n",
    "# e4e 00005_snapthos_1200\n",
    "mean_msssim_losses['e4e_00005'] = calculate_msssim_losses(generated_path_00005, scores_save_path_00005)\n",
    "# PTI \n",
    "mean_msssim_losses['PTI'] = calculate_msssim_losses(generated_path_pti, scores_save_path_pti)\n",
    "# Restyle \n",
    "mean_msssim_losses['Restyle'] = calculate_msssim_losses(generated_path_restyle, scores_save_path_restyle)\n",
    "# Hyperstyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e4e_00003': 0.8283094537174898,\n",
       " 'e4e_00005': 0.8702037330478105,\n",
       " 'PTI': 0.9450018156766892,\n",
       " 'Restyle': 0.8918951418669431}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{DATA_PATH}/Metrics/MSSSIM/MSSSIM_Results.pkl\", 'wb') as f:\n",
    "    pickle.dump(mean_msssim_losses, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "mean_msssim_losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
