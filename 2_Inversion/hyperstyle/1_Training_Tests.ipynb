{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../hyperstyle/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8,\n",
      " 'board_interval': 50,\n",
      " 'checkpoint_path': None,\n",
      " 'dataset_type': 'zalando_germany_pre_extract',\n",
      " 'encoder_type': 'SharedWeightsHyperNetResNet',\n",
      " 'exp_dir': '/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/setup_test/',\n",
      " 'id_lambda': 0.0,\n",
      " 'image_interval': 500,\n",
      " 'input_nc': 6,\n",
      " 'l2_lambda': 1.0,\n",
      " 'layers_to_tune': '0,2,3,5,6,8,9,11,12,14,15,17,18,20,21,23,24',\n",
      " 'learning_rate': 0.0001,\n",
      " 'load_w_encoder': True,\n",
      " 'lpips_lambda': 0.8,\n",
      " 'max_steps': 500000,\n",
      " 'max_val_batches': 150,\n",
      " 'moco_lambda': 0.5,\n",
      " 'n_iters_per_batch': 5,\n",
      " 'optim_name': 'ranger',\n",
      " 'output_size': 512,\n",
      " 'save_interval': 2000,\n",
      " 'stylegan_weights': '/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512_network-snapshot-001200.pt',\n",
      " 'test_batch_size': 8,\n",
      " 'test_workers': 8,\n",
      " 'train_decoder': False,\n",
      " 'val_interval': 2000,\n",
      " 'w_encoder_checkpoint_path': '/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/faces_w_encoder.pt',\n",
      " 'w_encoder_type': 'WEncoder',\n",
      " 'workers': 8}\n",
      "Loading hypernet weights from resnet34!\n",
      "Loading decoder weights from pretrained path: /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512_network-snapshot-001200.pt\n",
      "Loading pretrained W encoder...\n",
      "Using WEncoder\n",
      "Loading WEncoder from checkpoint: /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/faces_w_encoder.pt\n",
      "Traceback (most recent call last):\n",
      "  File \"scripts/train.py\", line 32, in <module>\n",
      "    main()\n",
      "  File \"scripts/train.py\", line 19, in main\n",
      "    coach = Coach(opts)\n",
      "  File \"./training/coach_hyperstyle.py\", line 35, in __init__\n",
      "    self.net = HyperStyle(self.opts).to(self.device)\n",
      "  File \"./models/hyperstyle.py\", line 26, in __init__\n",
      "    self.load_weights()\n",
      "  File \"./models/hyperstyle.py\", line 62, in load_weights\n",
      "    self.w_encoder = self.__get_pretrained_w_encoder()\n",
      "  File \"./models/hyperstyle.py\", line 170, in __get_pretrained_w_encoder\n",
      "    w_net = pSp(opts_w_encoder)\n",
      "  File \"./models/encoders/psp.py\", line 33, in __init__\n",
      "    self.load_weights()\n",
      "  File \"./models/encoders/psp.py\", line 47, in load_weights\n",
      "    self.decoder.load_state_dict(get_keys(ckpt, 'decoder'), strict=True)\n",
      "  File \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1052, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for Generator:\n",
      "\tUnexpected key(s) in state_dict: \"convs.14.conv.weight\", \"convs.14.conv.blur.kernel\", \"convs.14.conv.modulation.weight\", \"convs.14.conv.modulation.bias\", \"convs.14.noise.weight\", \"convs.14.activate.bias\", \"convs.15.conv.weight\", \"convs.15.conv.modulation.weight\", \"convs.15.conv.modulation.bias\", \"convs.15.noise.weight\", \"convs.15.activate.bias\", \"to_rgbs.7.bias\", \"to_rgbs.7.upsample.kernel\", \"to_rgbs.7.conv.weight\", \"to_rgbs.7.conv.modulation.weight\", \"to_rgbs.7.conv.modulation.bias\", \"noises.noise_15\", \"noises.noise_16\". \n"
     ]
    }
   ],
   "source": [
    "CMD = \"\"\" python scripts/train.py \\\n",
    "    --dataset_type=zalando_germany_pre_extract \\\n",
    "    --encoder_type=SharedWeightsHyperNetResNet \\\n",
    "    --exp_dir=/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/setup_test/ \\\n",
    "    --stylegan_weights /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512_network-snapshot-001200.pt \\\n",
    "    --workers=8 \\\n",
    "    --batch_size=8 \\\n",
    "    --test_batch_size=8 \\\n",
    "    --test_workers=8 \\\n",
    "    --val_interval=2000 \\\n",
    "    --save_interval=2000 \\\n",
    "    --image_interval=500 \\\n",
    "    --lpips_lambda=0.8 \\\n",
    "    --l2_lambda=1 \\\n",
    "    --id_lambda=0 \\\n",
    "    --moco_lambda=0.5 \\\n",
    "    --n_iters_per_batch=5 \\\n",
    "    --max_val_batches=150 \\\n",
    "    --output_size=512 \\\n",
    "    --input_nc=6 \\\n",
    "    --load_w_encoder \\\n",
    "    --w_encoder_checkpoint_path=/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/faces_w_encoder.pt\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "!{CMD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMD = \"\"\" python scripts/train.py \\\n",
    "#     --dataset_type=zalando_germany_encode \\\n",
    "#     --encoder_type=SharedWeightsHyperNetResNet \\\n",
    "#     --exp_dir=/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/setup_test/ \\\n",
    "#     --stylegan_weights /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512_network-snapshot-001200.pt \\\n",
    "#     --workers=8 \\\n",
    "#     --batch_size=8 \\\n",
    "#     --test_batch_size=8 \\\n",
    "#     --test_workers=8 \\\n",
    "#     --val_interval=2000 \\\n",
    "#     --save_interval=2000 \\\n",
    "#     --image_interval=500\n",
    "#     --lpips_lambda=0.8 \\\n",
    "#     --l2_lambda=1 \\\n",
    "#     --id_lambda=0 \\\n",
    "#     --moco_lambda=0.5 \\\n",
    "#     --n_iters_per_batch=5 \\\n",
    "#     --max_val_batches=150 \\\n",
    "#     --output_size=512 \\\n",
    "#     --w_encoder_type=ResNetProgressiveBackboneEncoder \\\n",
    "#     --input_nc=6 \\\n",
    "#     --load_w_encoder \\\n",
    "#     --w_encoder_checkpoint_path=/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/restyle/setup_test/checkpoints/iteration_0.pt \\\n",
    "# \"\"\"\n",
    "\n",
    "# !{CMD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
