{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../../restyle-encoder/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8,\n",
      " 'board_interval': 50,\n",
      " 'checkpoint_path': None,\n",
      " 'd_reg_every': 16,\n",
      " 'dataset_type': 'zalando_germany_encode',\n",
      " 'delta_norm': 2,\n",
      " 'delta_norm_lambda': 0.0002,\n",
      " 'encoder_type': 'ResNetProgressiveBackboneEncoder',\n",
      " 'exp_dir': '/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/restyle/setup_test/',\n",
      " 'id_lambda': 0.0,\n",
      " 'image_interval': 100,\n",
      " 'input_nc': 6,\n",
      " 'l2_lambda': 1.0,\n",
      " 'learning_rate': 0.0001,\n",
      " 'lpips_lambda': 0.8,\n",
      " 'max_steps': 500000,\n",
      " 'moco_lambda': 0.5,\n",
      " 'n_iters_per_batch': 5,\n",
      " 'optim_name': 'ranger',\n",
      " 'output_size': 512,\n",
      " 'progressive_start': None,\n",
      " 'progressive_step_every': 2000,\n",
      " 'progressive_steps': None,\n",
      " 'r1': 10,\n",
      " 'resume_training_from_ckpt': None,\n",
      " 'save_interval': 1,\n",
      " 'save_training_data': False,\n",
      " 'start_from_latent_avg': True,\n",
      " 'stylegan_weights': '/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512_network-snapshot-001200.pt',\n",
      " 'sub_exp_dir': None,\n",
      " 'test_batch_size': 8,\n",
      " 'test_workers': 8,\n",
      " 'train_decoder': False,\n",
      " 'update_param_list': None,\n",
      " 'use_w_pool': False,\n",
      " 'val_interval': 5000,\n",
      " 'w_discriminator_lambda': 0,\n",
      " 'w_discriminator_lr': 2e-05,\n",
      " 'w_norm_lambda': 0.0,\n",
      " 'w_pool_size': 50,\n",
      " 'workers': 8}\n",
      "Loading encoders weights from resnet34!\n",
      "Loading decoder weights from pretrained path: /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512_network-snapshot-001200.pt\n",
      "Loading MOCO model from path: /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/moco_v2_800ep_pretrain.pt\n",
      "Loading dataset for zalando_germany_encode\n",
      "Number of training samples: 12654\n",
      "Number of test samples: 1406\n",
      "./training/ranger.py:123: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "Metrics for train, step 0\n",
      "\tloss_l2 =  0.29034876823425293\n",
      "\tloss_lpips =  0.3382713794708252\n",
      "\tloss_moco =  0.30471259355545044\n",
      "\tid_improve =  -0.3047126680612564\n",
      "\tloss =  0.7133221626281738\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py\", line 372, in save\n"
     ]
    }
   ],
   "source": [
    "CMD = \"\"\"python scripts/train_restyle_e4e.py \\\n",
    "    --dataset_type=zalando_germany_encode \\\n",
    "    --encoder_type=ResNetProgressiveBackboneEncoder \\\n",
    "    --exp_dir=/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/restyle/setup_test/ \\\n",
    "    --stylegan_weights /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/hyperstyle/pretrained/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512_network-snapshot-001200.pt \\\n",
    "    --workers=8 \\\n",
    "    --batch_size=8 \\\n",
    "    --test_batch_size=8 \\\n",
    "    --test_workers=8 \\\n",
    "    --val_interval=5000 \\\n",
    "    --save_interval=1 \\\n",
    "    --start_from_latent_avg \\\n",
    "    --lpips_lambda=0.8 \\\n",
    "    --l2_lambda=1 \\\n",
    "    --w_norm_lambda=0 \\\n",
    "    --id_lambda=0 \\\n",
    "    --moco_lambda=0.5 \\\n",
    "    --input_nc=6 \\\n",
    "    --n_iters_per_batch=5 \\\n",
    "    --output_size=512 \\\n",
    "\"\"\"\n",
    "!{CMD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
