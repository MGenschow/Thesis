{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np \n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "if platform.system() == 'Darwin':\n",
    "    DATA_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Thesis\"\n",
    "elif platform.system() == 'Linux':\n",
    "    DATA_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis\"\n",
    "\n",
    "current_wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda as device\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Using {device} as device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pti_experiments_path = f\"{DATA_PATH}/Models/PTI/experiments/\"\n",
    "pti_input_images_path = f\"{DATA_PATH}/Zalando_Germany_Dataset/dresses/images/pti_images/sample/\"\n",
    "generated_images_output_path = f\"{DATA_PATH}/Generated_Images/PTI/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_images = glob(f\"{pti_input_images_path}*.jpg\")\n",
    "input_images = [elem.split('/')[-1] for elem in input_images]\n",
    "len(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(f'{ROOT_PATH}/stylegan2-ada-pytorch/')\n",
    "def invert_from_sku(sku):\n",
    "    # Get correct generator:\n",
    "    model_path = f\"{pti_experiments_path}checkpoints/model_whole_sample_{sku.split('.')[0]}.pt\"\n",
    "    G_PTI = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    G_PTI = G_PTI.to(device)\n",
    "\n",
    "    # Load corresponding latent embedding\n",
    "    latent_path = f\"{pti_experiments_path}embeddings/zalando_germany/PTI/{sku.split('.')[0]}/0.pt\"\n",
    "    latent = torch.load(latent_path, map_location=torch.device('cpu'))\n",
    "    latent = latent.to(device)\n",
    "\n",
    "    #  Create image from finetuned-PTI model\n",
    "    img = G_PTI.synthesis(latent, force_fp32=True)\n",
    "    img_perm = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    img_pti = Image.fromarray(img_perm[0].cpu().numpy(), 'RGB')\n",
    "    return img_pti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [10:08<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "for sku in tqdm(input_images):\n",
    "    img = invert_from_sku(sku)\n",
    "    img.save(f\"{generated_images_output_path}{sku}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
