{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations: \n",
    "\n",
    "To run a successfull training one needs to prepare multiple things:\n",
    "\n",
    "1. Create a custom training and test set using `e4e_dataset_preparation.ipynb`\n",
    "2. Convert the trained StyleGAN2-Ada weight from the official NVIDIA implementation to StyleGAN2 weights compatible with rosinality's implementations\n",
    "3. Load all the necessary auxiliary models into the `Models/e4e/pretrained/` directory in the Data folder\n",
    "4. Adapt all the paths in `configs/paths_config.py` and `configs/data_configs.py` to the custom training data and the model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../encoder4editing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8,\n",
      " 'board_interval': 50,\n",
      " 'checkpoint_path': None,\n",
      " 'd_reg_every': 16,\n",
      " 'dataset_type': 'zalando_germany_encode',\n",
      " 'delta_norm': 2,\n",
      " 'delta_norm_lambda': 0.0002,\n",
      " 'encoder_type': 'Encoder4Editing',\n",
      " 'exp_dir': '/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/setup/',\n",
      " 'id_lambda': 0.5,\n",
      " 'image_interval': 200,\n",
      " 'keep_optimizer': False,\n",
      " 'l2_lambda': 1.0,\n",
      " 'learning_rate': 0.001,\n",
      " 'lpips_lambda': 0.8,\n",
      " 'lpips_type': 'alex',\n",
      " 'max_steps': 200000,\n",
      " 'optim_name': 'ranger',\n",
      " 'progressive_start': 20000,\n",
      " 'progressive_step_every': 2000,\n",
      " 'progressive_steps': [0,\n",
      "                       20000,\n",
      "                       22000,\n",
      "                       24000,\n",
      "                       26000,\n",
      "                       28000,\n",
      "                       30000,\n",
      "                       32000,\n",
      "                       34000,\n",
      "                       36000,\n",
      "                       38000,\n",
      "                       40000,\n",
      "                       42000,\n",
      "                       44000,\n",
      "                       46000,\n",
      "                       48000],\n",
      " 'r1': 10,\n",
      " 'resume_training_from_ckpt': None,\n",
      " 'save_interval': 2000,\n",
      " 'save_training_data': True,\n",
      " 'start_from_latent_avg': True,\n",
      " 'stylegan_size': 512,\n",
      " 'stylegan_weights': '/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/pretrained/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512_network-snapshot-001200.pt',\n",
      " 'sub_exp_dir': 'setup',\n",
      " 'test_batch_size': 4,\n",
      " 'test_workers': 4,\n",
      " 'train_decoder': False,\n",
      " 'update_param_list': None,\n",
      " 'use_w_pool': True,\n",
      " 'val_interval': 2000,\n",
      " 'w_discriminator_lambda': 0.1,\n",
      " 'w_discriminator_lr': 2e-05,\n",
      " 'w_pool_size': 50,\n",
      " 'workers': 8}\n",
      "Loading encoders weights from irse50!\n",
      "Loading decoder weights from pretrained!\n",
      "Loading MOCO model from path: /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/pretrained/moco_v2_800ep_pretrain.pt\n",
      "Loading dataset for zalando_germany_encode\n",
      "Number of training samples: 12654\n",
      "Number of test samples: 1406\n",
      "Changed progressive stage to:  ProgressiveStage.WTraining\n",
      "./training/ranger.py:123: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "Metrics for train, step 0\n",
      "\td_real_loss =  0.7069041728973389\n",
      "\td_fake_loss =  0.6953022480010986\n",
      "\tdiscriminator_loss =  1.4022064208984375\n",
      "\tdiscriminator_r1_loss =  0.16334094107151031\n",
      "\tencoder_discriminator_loss =  0.6957195997238159\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.2503011226654053\n",
      "\tid_improve =  -0.25030113011598587\n",
      "\tloss_l2 =  0.2044072151184082\n",
      "\tloss_lpips =  0.33524656295776367\n",
      "\tloss =  0.6673270463943481\n",
      "Metrics for train, step 50\n",
      "\td_real_loss =  0.3871334195137024\n",
      "\td_fake_loss =  0.5042324066162109\n",
      "\tdiscriminator_loss =  0.8913658261299133\n",
      "\tencoder_discriminator_loss =  0.9346636533737183\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.23919495940208435\n",
      "\tid_improve =  -0.23919492959976196\n",
      "\tloss_l2 =  0.2374831885099411\n",
      "\tloss_lpips =  0.34387078881263733\n",
      "\tloss =  0.7256436347961426\n",
      "Metrics for train, step 100\n",
      "\td_real_loss =  0.16536420583724976\n",
      "\td_fake_loss =  0.19397780299186707\n",
      "\tdiscriminator_loss =  0.3593420088291168\n",
      "\tencoder_discriminator_loss =  1.7492165565490723\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.2411043494939804\n",
      "\tid_improve =  -0.24110431969165802\n",
      "\tloss_l2 =  0.09987203776836395\n",
      "\tloss_lpips =  0.32527458667755127\n",
      "\tloss =  0.6555655002593994\n",
      "Metrics for train, step 150\n",
      "\td_real_loss =  0.12231038510799408\n",
      "\td_fake_loss =  0.18685942888259888\n",
      "\tdiscriminator_loss =  0.30916982889175415\n",
      "\tencoder_discriminator_loss =  1.7965524196624756\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.20764946937561035\n",
      "\tid_improve =  -0.20764946192502975\n",
      "\tloss_l2 =  0.16734978556632996\n",
      "\tloss_lpips =  0.3501192331314087\n",
      "\tloss =  0.7309252023696899\n",
      "Metrics for train, step 200\n",
      "\td_real_loss =  0.1277829110622406\n",
      "\td_fake_loss =  0.11284712702035904\n",
      "\tdiscriminator_loss =  0.24063003063201904\n",
      "\tencoder_discriminator_loss =  1.8029344081878662\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.19959339499473572\n",
      "\tid_improve =  -0.19959334284067154\n",
      "\tloss_l2 =  0.09191956371068954\n",
      "\tloss_lpips =  0.25059929490089417\n",
      "\tloss =  0.5724891424179077\n",
      "Metrics for train, step 250\n",
      "\td_real_loss =  0.13655132055282593\n",
      "\td_fake_loss =  0.1952625960111618\n",
      "\tdiscriminator_loss =  0.3318139314651489\n",
      "\tencoder_discriminator_loss =  1.6978468894958496\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.38233980536460876\n",
      "\tid_improve =  -0.38233982026576996\n",
      "\tloss_l2 =  0.11192955821752548\n",
      "\tloss_lpips =  0.3362903892993927\n",
      "\tloss =  0.7419164776802063\n",
      "Metrics for train, step 300\n",
      "\td_real_loss =  0.12828008830547333\n",
      "\td_fake_loss =  0.14862114191055298\n",
      "\tdiscriminator_loss =  0.2769012451171875\n",
      "\tencoder_discriminator_loss =  1.9246838092803955\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.18129251897335052\n",
      "\tid_improve =  -0.18129251897335052\n",
      "\tloss_l2 =  0.08884511888027191\n",
      "\tloss_lpips =  0.24940182268619537\n",
      "\tloss =  0.5714812278747559\n",
      "Metrics for train, step 350\n",
      "\td_real_loss =  0.13060036301612854\n",
      "\td_fake_loss =  0.19687655568122864\n",
      "\tdiscriminator_loss =  0.3274769186973572\n",
      "\tencoder_discriminator_loss =  1.6730003356933594\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.23588566482067108\n",
      "\tid_improve =  -0.2358856424689293\n",
      "\tloss_l2 =  0.14522455632686615\n",
      "\tloss_lpips =  0.29289865493774414\n",
      "\tloss =  0.6647863388061523\n",
      "Metrics for train, step 400\n",
      "\td_real_loss =  0.11646190285682678\n",
      "\td_fake_loss =  0.18073564767837524\n",
      "\tdiscriminator_loss =  0.297197550535202\n",
      "\tdiscriminator_r1_loss =  5.648924827575684\n",
      "\tencoder_discriminator_loss =  1.6350483894348145\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.195870041847229\n",
      "\tid_improve =  -0.1958700269460678\n",
      "\tloss_l2 =  0.1538214534521103\n",
      "\tloss_lpips =  0.3045000731945038\n",
      "\tloss =  0.6588613986968994\n",
      "Metrics for train, step 450\n",
      "\td_real_loss =  0.15237939357757568\n",
      "\td_fake_loss =  0.23989248275756836\n",
      "\tdiscriminator_loss =  0.39227187633514404\n",
      "\tencoder_discriminator_loss =  1.5281295776367188\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.1232619509100914\n",
      "\tid_improve =  -0.1232619360089302\n",
      "\tloss_l2 =  0.08420049399137497\n",
      "\tloss_lpips =  0.2158317267894745\n",
      "\tloss =  0.4713098108768463\n",
      "Metrics for train, step 500\n",
      "\td_real_loss =  0.1446356475353241\n",
      "\td_fake_loss =  0.23308327794075012\n",
      "\tdiscriminator_loss =  0.3777189254760742\n",
      "\tencoder_discriminator_loss =  1.5447096824645996\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.16230154037475586\n",
      "\tid_improve =  -0.16230148077011108\n",
      "\tloss_l2 =  0.10631731152534485\n",
      "\tloss_lpips =  0.25374025106430054\n",
      "\tloss =  0.5449312329292297\n",
      "Metrics for train, step 550\n",
      "\td_real_loss =  0.17334231734275818\n",
      "\td_fake_loss =  0.2523067891597748\n",
      "\tdiscriminator_loss =  0.42564910650253296\n",
      "\tencoder_discriminator_loss =  1.487318515777588\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.20079195499420166\n",
      "\tid_improve =  -0.20079194009304047\n",
      "\tloss_l2 =  0.06781995296478271\n",
      "\tloss_lpips =  0.2296130359172821\n",
      "\tloss =  0.5006382465362549\n",
      "Metrics for train, step 600\n",
      "\td_real_loss =  0.18334582448005676\n",
      "\td_fake_loss =  0.24193207919597626\n",
      "\tdiscriminator_loss =  0.4252778887748718\n",
      "\tencoder_discriminator_loss =  1.5567749738693237\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.11764325201511383\n",
      "\tid_improve =  -0.11764325201511383\n",
      "\tloss_l2 =  0.10279490053653717\n",
      "\tloss_lpips =  0.21416473388671875\n",
      "\tloss =  0.48862579464912415\n",
      "Metrics for train, step 650\n",
      "\td_real_loss =  0.16308510303497314\n",
      "\td_fake_loss =  0.2855943441390991\n",
      "\tdiscriminator_loss =  0.44867944717407227\n",
      "\tencoder_discriminator_loss =  1.3622181415557861\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.1811542958021164\n",
      "\tid_improve =  -0.1811542809009552\n",
      "\tloss_l2 =  0.10677850246429443\n",
      "\tloss_lpips =  0.25471776723861694\n",
      "\tloss =  0.537351667881012\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model_path = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/pretrained/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512_network-snapshot-001200.pt\"\n",
    "CMD =f\"\"\"\n",
    "    python scripts/train.py \\\n",
    "    --exp_dir=/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/setup/ \\\n",
    "    --sub_exp_dir=setup \\\n",
    "    --dataset_type zalando_germany_encode \\\n",
    "    --workers 8 \\\n",
    "    --batch_size 8 \\\n",
    "    --test_batch_size 4 \\\n",
    "    --test_workers 4 \\\n",
    "    --stylegan_weights {model_path} \\\n",
    "    --stylegan_size 512 \\\n",
    "    --learning_rate=0.001 \\\n",
    "    --start_from_latent_avg \\\n",
    "    --use_w_pool \\\n",
    "    --w_discriminator_lambda 0.1 \\\n",
    "    --progressive_start 20000 \\\n",
    "    --id_lambda 0.5 \\\n",
    "    --max_steps 200000 \\\n",
    "    --save_interval 2000 \\\n",
    "    --val_interval 2000 \\\n",
    "    --image_interval 500 \\\n",
    "    --save_training_data \\\n",
    "\"\"\"\n",
    "!{CMD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
