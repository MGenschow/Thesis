{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations: \n",
    "\n",
    "To run a successfull training one needs to prepare multiple things:\n",
    "\n",
    "1. Create a custom training and test set using `e4e_dataset_preparation.ipynb`\n",
    "2. Convert the trained StyleGAN2-Ada weight from the official NVIDIA implementation to StyleGAN2 weights compatible with rosinality's implementations\n",
    "3. Load all the necessary auxiliary models into the `Models/e4e/pretrained/` directory in the Data folder\n",
    "4. Adapt all the paths in `configs/paths_config.py` and `configs/data_configs.py` to the custom training data and the model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../encoder4editing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8,\n",
      " 'board_interval': 50,\n",
      " 'checkpoint_path': None,\n",
      " 'd_reg_every': 16,\n",
      " 'dataset_type': 'zalando_germany_encode',\n",
      " 'delta_norm': 2,\n",
      " 'delta_norm_lambda': 0.0002,\n",
      " 'encoder_type': 'Encoder4Editing',\n",
      " 'exp_dir': '/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/experiments/',\n",
      " 'id_lambda': 0.5,\n",
      " 'image_interval': 200,\n",
      " 'keep_optimizer': False,\n",
      " 'l2_lambda': 1.0,\n",
      " 'learning_rate': 0.001,\n",
      " 'lpips_lambda': 0.8,\n",
      " 'lpips_type': 'alex',\n",
      " 'max_steps': 200000,\n",
      " 'optim_name': 'ranger',\n",
      " 'progressive_start': 20000,\n",
      " 'progressive_step_every': 2000,\n",
      " 'progressive_steps': [0,\n",
      "                       20000,\n",
      "                       22000,\n",
      "                       24000,\n",
      "                       26000,\n",
      "                       28000,\n",
      "                       30000,\n",
      "                       32000,\n",
      "                       34000,\n",
      "                       36000,\n",
      "                       38000,\n",
      "                       40000,\n",
      "                       42000,\n",
      "                       44000,\n",
      "                       46000,\n",
      "                       48000],\n",
      " 'r1': 10,\n",
      " 'resume_training_from_ckpt': None,\n",
      " 'save_interval': 2000,\n",
      " 'save_training_data': True,\n",
      " 'start_from_latent_avg': True,\n",
      " 'stylegan_size': 512,\n",
      " 'stylegan_weights': '/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/pretrained/stylegan2_ada_zalando_germany.pt',\n",
      " 'sub_exp_dir': 'setup',\n",
      " 'test_batch_size': 4,\n",
      " 'test_workers': 4,\n",
      " 'train_decoder': False,\n",
      " 'update_param_list': None,\n",
      " 'use_w_pool': True,\n",
      " 'val_interval': 2000,\n",
      " 'w_discriminator_lambda': 0.1,\n",
      " 'w_discriminator_lr': 2e-05,\n",
      " 'w_pool_size': 50,\n",
      " 'workers': 8}\n",
      "Loading encoders weights from irse50!\n",
      "Loading decoder weights from pretrained!\n",
      "Loading MOCO model from path: /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/pretrained/moco_v2_800ep_pretrain.pt\n",
      "Loading dataset for zalando_germany_encode\n",
      "Number of training samples: 11248\n",
      "Number of test samples: 2812\n",
      "Changed progressive stage to:  ProgressiveStage.WTraining\n",
      "./training/ranger.py:123: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "Metrics for train, step 0\n",
      "\td_real_loss =  0.705941915512085\n",
      "\td_fake_loss =  0.6973575353622437\n",
      "\tdiscriminator_loss =  1.4032994508743286\n",
      "\tdiscriminator_r1_loss =  0.1646551489830017\n",
      "\tencoder_discriminator_loss =  0.6942093968391418\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.28062766790390015\n",
      "\tid_improve =  -0.28062763065099716\n",
      "\tloss_l2 =  0.24991469085216522\n",
      "\tloss_lpips =  0.32227468490600586\n",
      "\tloss =  0.7174692153930664\n",
      "Metrics for train, step 50\n",
      "\td_real_loss =  0.3833131194114685\n",
      "\td_fake_loss =  0.49513736367225647\n",
      "\tdiscriminator_loss =  0.8784505128860474\n",
      "\tencoder_discriminator_loss =  0.9465722441673279\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.19007477164268494\n",
      "\tid_improve =  -0.19007477164268494\n",
      "\tloss_l2 =  0.11479903757572174\n",
      "\tloss_lpips =  0.2719217538833618\n",
      "\tloss =  0.5220310688018799\n",
      "Metrics for train, step 100\n",
      "\td_real_loss =  0.15898479521274567\n",
      "\td_fake_loss =  0.1795269250869751\n",
      "\tdiscriminator_loss =  0.33851170539855957\n",
      "\tencoder_discriminator_loss =  1.8180525302886963\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.1991838812828064\n",
      "\tid_improve =  -0.1991838812828064\n",
      "\tloss_l2 =  0.0904729962348938\n",
      "\tloss_lpips =  0.28086617588996887\n",
      "\tloss =  0.5965631008148193\n",
      "Metrics for train, step 150\n",
      "\td_real_loss =  0.12127624452114105\n",
      "\td_fake_loss =  0.276935875415802\n",
      "\tdiscriminator_loss =  0.39821213483810425\n",
      "\tencoder_discriminator_loss =  1.5762503147125244\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.24725502729415894\n",
      "\tid_improve =  -0.24725502729415894\n",
      "\tloss_l2 =  0.13577435910701752\n",
      "\tloss_lpips =  0.28984755277633667\n",
      "\tloss =  0.6489049792289734\n",
      "Metrics for train, step 200\n",
      "\td_real_loss =  0.12395545095205307\n",
      "\td_fake_loss =  0.12747012078762054\n",
      "\tdiscriminator_loss =  0.251425564289093\n",
      "\tencoder_discriminator_loss =  1.4974675178527832\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.24430665373802185\n",
      "\tid_improve =  -0.24430665001273155\n",
      "\tloss_l2 =  0.1324167251586914\n",
      "\tloss_lpips =  0.260101854801178\n",
      "\tloss =  0.6123982667922974\n",
      "Metrics for train, step 250\n",
      "\td_real_loss =  0.13878515362739563\n",
      "\td_fake_loss =  0.19430086016654968\n",
      "\tdiscriminator_loss =  0.3330860137939453\n",
      "\tencoder_discriminator_loss =  1.6158198118209839\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.25643470883369446\n",
      "\tid_improve =  -0.25643473863601685\n",
      "\tloss_l2 =  0.12926167249679565\n",
      "\tloss_lpips =  0.27416539192199707\n",
      "\tloss =  0.6383933424949646\n",
      "Metrics for train, step 300\n",
      "\td_real_loss =  0.13513964414596558\n",
      "\td_fake_loss =  0.14389345049858093\n",
      "\tdiscriminator_loss =  0.2790330946445465\n",
      "\tencoder_discriminator_loss =  2.042849540710449\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.24480696022510529\n",
      "\tid_improve =  -0.24480696022510529\n",
      "\tloss_l2 =  0.09077253937721252\n",
      "\tloss_lpips =  0.25987064838409424\n",
      "\tloss =  0.6253575086593628\n",
      "Metrics for train, step 350\n",
      "\td_real_loss =  0.12997876107692719\n",
      "\td_fake_loss =  0.14620502293109894\n",
      "\tdiscriminator_loss =  0.2761837840080261\n",
      "\tencoder_discriminator_loss =  1.983729600906372\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.22841335833072662\n",
      "\tid_improve =  -0.22841329872608185\n",
      "\tloss_l2 =  0.15351581573486328\n",
      "\tloss_lpips =  0.31916388869285583\n",
      "\tloss =  0.7214266061782837\n",
      "Metrics for train, step 400\n",
      "\td_real_loss =  0.10336995124816895\n",
      "\td_fake_loss =  0.1786658763885498\n",
      "\tdiscriminator_loss =  0.28203582763671875\n",
      "\tdiscriminator_r1_loss =  5.358877182006836\n",
      "\tencoder_discriminator_loss =  1.778428077697754\n",
      "\ttotal_delta_loss =  0.0\n",
      "\tloss_id =  0.13742375373840332\n",
      "\tid_improve =  -0.13742372393608093\n",
      "\tloss_l2 =  0.06869100779294968\n",
      "\tloss_lpips =  0.24787332117557526\n",
      "\tloss =  0.5135443210601807\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"scripts/train.py\", line 88, in <module>\n",
      "    main()\n",
      "  File \"scripts/train.py\", line 29, in main\n",
      "    coach.train()\n",
      "  File \"./training/coach.py\", line 114, in train\n",
      "    x, y, y_hat, latent = self.forward(batch)\n",
      "  File \"./training/coach.py\", line 282, in forward\n",
      "    y_hat, latent = self.net.forward(x, return_latents=True)\n",
      "  File \"./models/psp.py\", line 62, in forward\n",
      "    codes = self.encoder(x)\n",
      "  File \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"./models/encoders/psp_encoders.py\", line 178, in forward\n",
      "    x = l(x)\n",
      "  File \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"./models/encoders/helpers.py\", line 119, in forward\n",
      "    res = self.res_layer(x)\n",
      "  File \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/miniconda3/envs/thesis/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\", line 111, in forward\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model_path = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/pretrained/stylegan2_ada_zalando_germany.pt\"\n",
    "CMD =f\"\"\"\n",
    "    python scripts/train.py \\\n",
    "    --exp_dir=/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/e4e/experiments/ \\\n",
    "    --sub_exp_dir=setup \\\n",
    "    --dataset_type zalando_germany_encode \\\n",
    "    --workers 8 \\\n",
    "    --batch_size 8 \\\n",
    "    --test_batch_size 4 \\\n",
    "    --test_workers 4 \\\n",
    "    --stylegan_weights {model_path} \\\n",
    "    --stylegan_size 512 \\\n",
    "    --learning_rate=0.001 \\\n",
    "    --start_from_latent_avg \\\n",
    "    --use_w_pool \\\n",
    "    --w_discriminator_lambda 0.1 \\\n",
    "    --progressive_start 20000 \\\n",
    "    --id_lambda 0.5 \\\n",
    "    --max_steps 200000 \\\n",
    "    --save_interval 2000 \\\n",
    "    --val_interval 2000 \\\n",
    "    --image_interval 200 \\\n",
    "    --save_training_data\n",
    "\"\"\"\n",
    "!{CMD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
