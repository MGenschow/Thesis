{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "if platform.system() == 'Darwin':\n",
    "    DATA_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Thesis\"\n",
    "elif platform.system() == 'Linux':\n",
    "    DATA_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis\"\n",
    "\n",
    "current_wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "except:\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "print(f\"Using {device} as device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Paths setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e4e_model_path = f\"{DATA_PATH}/Models/e4e/00005_snapshot_1200/setup/checkpoints/best_model.pt\"\n",
    "e4e_input_images_paths = [path for subdir in ['train', 'test'] for path in glob(f\"{DATA_PATH}/Zalando_Germany_Dataset/dresses/images/e4e_images/{subdir}/*.jpg\")]\n",
    "latents_save_dir = f\"{DATA_PATH}/Models/e4e/00005_snapshot_1200/inversions/\"\n",
    "reconstructions_save_dir = f\"{DATA_PATH}/Generated_Images/e4e/00005_snapshot_1200/\"\n",
    "sg2_generator_model_path = f\"{DATA_PATH}/Models/Stylegan2_Ada/Experiments/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512/network-snapshot-001200.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Get all Latent Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into e4e dir to import inference code\n",
    "os.chdir(f'{ROOT_PATH}/encoder4editing/')\n",
    "\n",
    "from scripts.inference import *\n",
    "\n",
    "# Setup Model\n",
    "net, opts = setup_model(e4e_model_path, device)\n",
    "generator = net.decoder\n",
    "generator.eval()\n",
    "\n",
    "# Get transforms\n",
    "dataset_args = data_configs.DATASETS[opts.dataset_type]\n",
    "transforms_dict = dataset_args['transforms'](opts).get_transforms()\n",
    "\n",
    "# Define inversion function\n",
    "def encode_from_path(image_path):\n",
    "    # Input\n",
    "    img_orig = Image.open(image_path).convert('RGB')\n",
    "    img = transforms_dict['transform_test'](img_orig)\n",
    "    img = img.reshape(-1, 3, 256, 256)\n",
    "    img = img.to(device).float()\n",
    "\n",
    "    latent = get_latents(net, img)\n",
    "    return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {e4e_input_images_paths} images\")\n",
    "\n",
    "\n",
    "all_latents = torch.zeros(len(e4e_input_images_paths), 1, 16, 512)\n",
    "all_paths = []\n",
    "for i, path in enumerate(tqdm(e4e_input_images_paths)):\n",
    "    sku = path.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "    latent = encode_from_path(path)\n",
    "    latent = latent.cpu().detach()\n",
    "\n",
    "    all_latents[i] = latent\n",
    "    all_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save latents tensor\n",
    "torch.save(all_latents, f\"{latents_save_dir}latents.pt\")\n",
    "# Save file paths\n",
    "with open(f\"{latents_save_dir}file_paths.pkl\", 'wb') as handle:\n",
    "    pickle.dump(all_paths, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate All Reconstructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Latents and File Paths\n",
    "latents = torch.load(f\"{latents_save_dir}latents.pt\")\n",
    "with open(f\"{latents_save_dir}file_paths.pkl\", 'rb') as f:\n",
    "    file_paths = pickle.load(f)\n",
    "\n",
    "# Create Latents Dict\n",
    "latents_dict = {}\n",
    "for i, file in enumerate(file_paths):\n",
    "    sku = file.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "    latents_dict[sku] = latents[i]\n",
    "# with open(f'{latents_save_dir}latents_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(latents_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize original custom SG2-Ada generator\n",
    "os.chdir(f\"{ROOT_PATH}/stylegan2-ada-pytorch/\")\n",
    "with open(sg2_generator_model_path, 'rb') as f:\n",
    "    architecture = pickle.load(f)\n",
    "    G = architecture['G_ema'].to(device)  # torch.nn.Module \n",
    "    D = architecture['D'].to(device)\n",
    "\n",
    "# Go back into current dir\n",
    "#os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_sku(sku):\n",
    "    latent = latents_dict[sku][0].unsqueeze(0).to(device)\n",
    "    img = G.synthesis(latent)\n",
    "    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    img = Image.fromarray(img[0].cpu().numpy(), 'RGB')\n",
    "    return img\n",
    "\n",
    "def generate_from_latent(latent):\n",
    "    img = G.synthesis(latent)\n",
    "    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    img = Image.fromarray(img[0].cpu().numpy(), 'RGB')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn([1,512], device = device)\n",
    "img = G(z, None, noise_mode = 'const')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "# Generate all Images and Save\n",
    "for sku in tqdm(latents_dict.keys()):\n",
    "    with io.capture_output() as captured:\n",
    "        img = generate_from_sku(sku)\n",
    "    img.save(f\"{reconstructions_save_dir}{sku}.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
