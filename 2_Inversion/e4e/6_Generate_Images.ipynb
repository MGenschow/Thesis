{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = \"../../../Data.nosync/\"\n",
    "save_path = f\"{DATA_PATH}/Models/e4e/experiments_default_lr/inversions/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in metadata\n",
    "metadata = json.load(open(f\"{DATA_PATH}Zalando_Germany_Dataset/dresses/metadata/dresses_metadata.json\", 'r'))\n",
    "metadata_df = pd.read_json(f\"{DATA_PATH}Zalando_Germany_Dataset/dresses/metadata/dresses_metadata.json\").T.reset_index().rename(columns={'index':'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in latents and file paths \n",
    "latents = torch.load(f\"{save_path}latents.pt\")\n",
    "with open(f\"{save_path}file_paths.pkl\", 'rb') as f:\n",
    "    file_paths = pickle.load(f)\n",
    "\n",
    "latents_dict = {}\n",
    "for i, file in enumerate(file_paths):\n",
    "    sku = file.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "    latents_dict[sku] = latents[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initalize original custom SG2-Ada generator\n",
    "os.chdir(\"../../stylegan2-ada-pytorch/\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "model_path = f\"../../Data.nosync/Models/Stylegan2_Ada/Experiments/00003-stylegan2_ada_images-mirror-auto2-kimg1000-resumeffhq512/network-snapshot-000920.pkl\"\n",
    "with open(model_path, 'rb') as f:\n",
    "    architecture = pickle.load(f)\n",
    "    G = architecture['G_ema'].to(device)  # torch.nn.Module \n",
    "    D = architecture['D'].to(device)\n",
    "\n",
    "os.chdir('../2_Inversion/e4e/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_sku(sku):\n",
    "    latent = latents_dict[sku][0].unsqueeze(0).to(device)\n",
    "    img = G.synthesis(latent)\n",
    "    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    img = Image.fromarray(img[0].cpu().numpy(), 'RGB')\n",
    "    return img\n",
    "\n",
    "def generate_from_latent(latent):\n",
    "    img = G.synthesis(latent)\n",
    "    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    img = Image.fromarray(img[0].cpu().numpy(), 'RGB')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate all Images and save as generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14060 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14060/14060 [06:50<00:00, 34.23it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dir = f\"{DATA_PATH}/Generated_Images/Zalando_Germany_Reconstructions/\"\n",
    "\n",
    "for sku in tqdm(latents_dict.keys()):\n",
    "    img = generate_from_sku(sku)\n",
    "    img.save(f\"{save_dir}{sku}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
