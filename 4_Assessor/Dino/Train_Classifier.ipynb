{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda as device\n",
      "Using cuda as device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/dinov2/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/dinov2/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/dinov2/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Custom Dino and Classifier Imports\n",
    "from dino_utils import prepare_data, Categories_Dataset\n",
    "from dino_utils import ClassifierModel, evaluate_model, train_model\n",
    "from dino_utils import set_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "if platform.system() == 'Darwin':\n",
    "    DATA_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Thesis\"\n",
    "elif platform.system() == 'Linux':\n",
    "    DATA_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis\"\n",
    "\n",
    "current_wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'sleeve_length'\n",
    "fake_data_name = 'hyperstyle_embeddings'\n",
    "retrain = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: sleeve_length\n",
      "\tNumber of classes: 11\n",
      "\tNumber of training samples: 22476\n",
      "\tNumber of testing samples: 5620\n"
     ]
    }
   ],
   "source": [
    "train_real, test_real = prepare_data(target, 'real_images_embeddings')\n",
    "train_fake, test_fake = prepare_data(target, fake_data_name)\n",
    "\n",
    "# Combine real and fake data\n",
    "train = ConcatDataset([train_real, train_fake])\n",
    "test = ConcatDataset([test_real, test_fake])\n",
    "\n",
    "print(f\"Target: {train_real.target}\")\n",
    "print(f\"\\tNumber of classes: {len(train_real.id2label)}\")\n",
    "\n",
    "print(f\"\\tNumber of training samples: {len(train)}\")\n",
    "print(f\"\\tNumber of testing samples: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda as device\n"
     ]
    }
   ],
   "source": [
    "## Model Parameters\n",
    "embeddings_shape = train_real[0][0].shape[0]\n",
    "num_classes = len(train_real.id2label)\n",
    "\n",
    "## Training Hyperparameters\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "LR = 5e-4\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "## Initialize Model and Optimizer\n",
    "device = set_device()\n",
    "model = ClassifierModel(embeddings_shape, num_classes)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "model_save_path = f\"{DATA_PATH}/Models/Assessor/DinoV2/Classifier/{target}_{fake_data_name}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Train Accuracy: 0.04765082754938601, Initial Test Accuracy: 0.050711743772241996\n",
      "Epoch 1/30, Loss: 0.7484436631202698, Train Accuracy: 0.7588093966898024, Test Accuracy: 0.7498220640569395\n",
      "Epoch 2/30, Loss: 0.5398092865943909, Train Accuracy: 0.7921338316426411, Test Accuracy: 0.7690391459074734\n",
      "Epoch 3/30, Loss: 0.6806285977363586, Train Accuracy: 0.806549208044136, Test Accuracy: 0.7729537366548043\n",
      "Epoch 4/30, Loss: 0.6368935704231262, Train Accuracy: 0.8240790176187934, Test Accuracy: 0.7832740213523132\n",
      "Epoch 5/30, Loss: 0.5095024704933167, Train Accuracy: 0.8248798718633209, Test Accuracy: 0.7846975088967971\n",
      "Epoch 6/30, Loss: 0.4697592258453369, Train Accuracy: 0.8396066915821321, Test Accuracy: 0.7886120996441282\n",
      "Epoch 7/30, Loss: 0.3804227411746979, Train Accuracy: 0.8411639081687133, Test Accuracy: 0.7743772241992882\n",
      "Epoch 8/30, Loss: 0.24855899810791016, Train Accuracy: 0.860606869549742, Test Accuracy: 0.7857651245551601\n",
      "Epoch 9/30, Loss: 0.5842955112457275, Train Accuracy: 0.8708400071187044, Test Accuracy: 0.7895017793594306\n",
      "Epoch 10/30, Loss: 0.378387987613678, Train Accuracy: 0.8681704929702794, Test Accuracy: 0.7882562277580071\n",
      "Epoch 11/30, Loss: 0.3890979290008545, Train Accuracy: 0.8806282256629293, Test Accuracy: 0.7927046263345195\n",
      "Epoch 12/30, Loss: 0.3153310716152191, Train Accuracy: 0.889393130450258, Test Accuracy: 0.7932384341637011\n",
      "Epoch 13/30, Loss: 0.4136812686920166, Train Accuracy: 0.8936198611852643, Test Accuracy: 0.7912811387900356\n",
      "Epoch 14/30, Loss: 0.3352377414703369, Train Accuracy: 0.8948211425520555, Test Accuracy: 0.7845195729537366\n",
      "Epoch 15/30, Loss: 0.3321848213672638, Train Accuracy: 0.904164442071543, Test Accuracy: 0.7896797153024911\n",
      "Epoch 16/30, Loss: 0.18626300990581512, Train Accuracy: 0.912528919736608, Test Accuracy: 0.7895017793594306\n",
      "Epoch 17/30, Loss: 0.2808481454849243, Train Accuracy: 0.9142196120306104, Test Accuracy: 0.7875444839857652\n",
      "Epoch 18/30, Loss: 0.45261985063552856, Train Accuracy: 0.9251201281366791, Test Accuracy: 0.7871886120996441\n",
      "Epoch 19/30, Loss: 0.21438349783420563, Train Accuracy: 0.9242302900872041, Test Accuracy: 0.7825622775800711\n",
      "Epoch 20/30, Loss: 0.2223033905029297, Train Accuracy: 0.9287684641395266, Test Accuracy: 0.7880782918149466\n",
      "Epoch 21/30, Loss: 0.34604373574256897, Train Accuracy: 0.9381562555614879, Test Accuracy: 0.7857651245551601\n",
      "Epoch 22/30, Loss: 0.15999750792980194, Train Accuracy: 0.9394910126357003, Test Accuracy: 0.7882562277580071\n",
      "Epoch 23/30, Loss: 0.16026030480861664, Train Accuracy: 0.948789820252714, Test Accuracy: 0.7838078291814946\n",
      "Epoch 24/30, Loss: 0.27095821499824524, Train Accuracy: 0.9455419113721303, Test Accuracy: 0.7953736654804271\n",
      "Epoch 25/30, Loss: 0.19136159121990204, Train Accuracy: 0.9403363587827015, Test Accuracy: 0.7886120996441282\n",
      "Epoch 26/30, Loss: 0.3296055495738983, Train Accuracy: 0.9522601886456665, Test Accuracy: 0.7900355871886121\n",
      "Epoch 27/30, Loss: 0.24042899906635284, Train Accuracy: 0.9601352553835202, Test Accuracy: 0.7868327402135231\n",
      "Epoch 28/30, Loss: 0.26708927750587463, Train Accuracy: 0.9555970813311977, Test Accuracy: 0.7852313167259787\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "if retrain or not os.path.exists(model_save_path):\n",
    "    train_model(model, NUM_EPOCHS, optimizer, loss_fn, train_loader, test_loader, model_save_path, device, log_every=10)\n",
    "else:\n",
    "    model = torch.load(model_save_path, map_location = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall Accuracy:\")\n",
    "print(f\"\\tTraining Set: {evaluate_model(model, DataLoader(train), device)}\")\n",
    "print(f\"\\tTesting Set: {evaluate_model(model, DataLoader(test), device)}\")\n",
    "\n",
    "print(\"Accuracy on real data:\")\n",
    "print(f\"\\tTraining Set: {evaluate_model(model, DataLoader(train_real), device)}\")\n",
    "print(f\"\\tTesting Set: {evaluate_model(model, DataLoader(test_real), device)}\")\n",
    "\n",
    "print(\"Accuracy on fake data:\")\n",
    "print(f\"\\tTraining Set: {evaluate_model(model, DataLoader(train_fake), device)}\")\n",
    "print(f\"\\tTesting Set: {evaluate_model(model, DataLoader(test_fake), device)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top N Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_loader = DataLoader(ConcatDataset([train_real, test_real]), batch_size=BATCH_SIZE, shuffle=False)\n",
    "fake_loader = DataLoader(ConcatDataset([train_fake, test_fake]), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_predictions(loader, n):\n",
    "    predictions = {}\n",
    "\n",
    "    for embeddings, labels, sku in loader:\n",
    "        output = model(embeddings.to(device))\n",
    "        prob, predicted = torch.topk(torch.softmax(output, 1), n)\n",
    "\n",
    "        for i in range(len(predicted)):\n",
    "            predictions[sku[i]] = [train_real.id2label[labels[i].item()]] + [train_real.id2label[predicted[i][j].item()] for j in range(n)] + [prob[i][j].item() for j in range(n)]\n",
    "\n",
    "    df = pd.DataFrame(predictions).T.reset_index()\n",
    "    df.columns = ['sku'] + ['target'] + [f'pred_{i}' for i in range(n)] + [f'prob_{i}' for i in range(n)]\n",
    "\n",
    "    df['top1_correct'] = df['target'] == df['pred_0']\n",
    "    for i in range(1, n):\n",
    "        df[f'top{i+1}_correct'] = df[f'top{i}_correct'] | (df['target'] == df[f'pred_{i}'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_predictions = get_top_n_predictions(real_loader, 3)\n",
    "fake_predictions = get_top_n_predictions(fake_loader, 3)\n",
    "\n",
    "real_predictions['dataset'] = real_predictions.sku.apply(lambda x: 'train' if x in train_real.df.sku.to_list() else 'test')\n",
    "fake_predictions['dataset'] = fake_predictions.sku.apply(lambda x: 'train' if x in train_fake.df.sku.to_list() else 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real Images:\")\n",
    "for dataset in ['train', 'test']:\n",
    "    print(f\"\\t{dataset.capitalize()} Set:\")\n",
    "    for i in range(3):\n",
    "        print(f\"\\t\\tTop {i+1}: {real_predictions[real_predictions.dataset == dataset][f'top{i+1}_correct'].mean()}\")\n",
    "\n",
    "print(\"Reconstructed Images:\")\n",
    "for dataset in ['train', 'test']:\n",
    "    print(f\"\\t{dataset.capitalize()} Set:\")\n",
    "    for i in range(3):\n",
    "        print(f\"\\t\\tTop {i+1}: {fake_predictions[fake_predictions.dataset == dataset][f'top{i+1}_correct'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Real Images:')\n",
    "display(real_predictions.groupby('target').top1_correct.mean().sort_values(ascending=False))\n",
    "\n",
    "print('Reconstructed Images:')\n",
    "fake_predictions.groupby('target').top1_correct.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(real_predictions.target, real_predictions.pred_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some misclassified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_missclassified_samples(miss, num_samples=5):\n",
    "    sample = miss.sample(num_samples)\n",
    "    fig, ax = plt.subplots(1, num_samples, figsize=(5 * num_samples, 10))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sku = sample.iloc[i].sku\n",
    "        img_path = f\"{DATA_PATH}/Generated_Images/hyperstyle/inference_results/4/{sku}.jpg\"\n",
    "        img = Image.open(img_path)\n",
    "        ax[i].imshow(img)\n",
    "\n",
    "        # Construct title string with predictions and their probabilities\n",
    "        title_text = f\"SKU: {sku}\\nTarget: {sample.iloc[i].target}\"\n",
    "        for j in range(3):  # Assuming there are always three predictions to display\n",
    "            pred_col = f'pred_{j}'\n",
    "            prob_col = f'prob_{j}'\n",
    "            title_text += f\"\\nPrediction {j + 1}: {sample.iloc[i][pred_col]} ({np.round(sample.iloc[i][prob_col], 2)})\"\n",
    "\n",
    "        ax[i].set_title(title_text)\n",
    "        ax[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = fake_predictions[fake_predictions.target != fake_predictions.pred_0]\n",
    "display_missclassified_samples(miss, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
