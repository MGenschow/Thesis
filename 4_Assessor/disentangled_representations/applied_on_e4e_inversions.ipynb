{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "if platform.system() == 'Darwin':\n",
    "    DATA_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Thesis\"\n",
    "elif platform.system() == 'Linux':\n",
    "    DATA_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis\"\n",
    "\n",
    "current_wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Base DinoV2 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from get_image_embeddings import compute_embeddings\n",
    "\n",
    "# models = ['vits14', 'vitb14']\n",
    "# samples = ['train', 'val']\n",
    "\n",
    "# for model in models:\n",
    "#     for sample in samples:\n",
    "#         compute_embeddings(\n",
    "#             dataset_name='zalando_germany',\n",
    "#             model_name=model,\n",
    "#             sample=sample)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Models without dCor and with Best dCor Parameters \n",
    "\n",
    "- Parameters found in [this file](https://github.com/aseembehl/disentangling-aesthetic/blob/dev_attribute_driven_rep/figures/figures.ipynb) in the original repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pipeline import train_and_validate\n",
    "# train_and_validate(\n",
    "#     dataset_name = 'zalando_germany',\n",
    "#     batch_size= 256,\n",
    "#     dcor_loss_factor=0,\n",
    "#     embeddings_name='vits14',\n",
    "#     grl_weight=None,\n",
    "#     hidden_dims_branches=[128, 128, 32],\n",
    "#     hidden_dims_common=[256, 256],\n",
    "#     lr=0.001,\n",
    "#     max_epochs=100,\n",
    "#     prediction_loss_factor=1,\n",
    "#     seed=4243\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_validate(\n",
    "#     dataset_name = 'zalando_germany',\n",
    "#     batch_size= 256,\n",
    "#     dcor_loss_factor=9.670528789445637,\n",
    "#     embeddings_name='vitb14',\n",
    "#     grl_weight=None,\n",
    "#     hidden_dims_branches=[256, 256, 256],\n",
    "#     hidden_dims_common=[256, 256],\n",
    "#     lr=0.001,\n",
    "#     max_epochs=100,\n",
    "#     prediction_loss_factor=1,\n",
    "#     seed=33\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Infer Disentangled Representations for all e4e Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset and dataloader. Number of images: 14060\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tu/tu_tu/tu_zxmav84/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/tu/tu_tu/tu_zxmav84/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/tu/tu_tu/tu_zxmav84/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/tu/tu_tu/tu_zxmav84/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TaskBranches model has 2,314,287 trainable parameters.\n",
      "\n",
      "Model architecture:\n",
      "TaskBranches(\n",
      "  (activation): ReLU()\n",
      "  (common_fc0): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (common_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_0_fc0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_0_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_0_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_0_task_0_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_0_task_1_out): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (branch_0_task_2_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_0_task_3_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_0_task_4_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_0_task_5_out): Linear(in_features=256, out_features=17, bias=True)\n",
      "  (branch_0_task_6_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_0_task_7_out): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (branch_0_task_8_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_1_fc0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_1_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_1_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_1_task_0_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_1_task_1_out): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (branch_1_task_2_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_1_task_3_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_1_task_4_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_1_task_5_out): Linear(in_features=256, out_features=17, bias=True)\n",
      "  (branch_1_task_6_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_1_task_7_out): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (branch_1_task_8_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_2_fc0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_2_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_2_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_2_task_0_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_2_task_1_out): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (branch_2_task_2_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_2_task_3_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_2_task_4_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_2_task_5_out): Linear(in_features=256, out_features=17, bias=True)\n",
      "  (branch_2_task_6_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_2_task_7_out): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (branch_2_task_8_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_3_fc0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_3_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_3_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_3_task_0_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_3_task_1_out): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (branch_3_task_2_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_3_task_3_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_3_task_4_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_3_task_5_out): Linear(in_features=256, out_features=17, bias=True)\n",
      "  (branch_3_task_6_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_3_task_7_out): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (branch_3_task_8_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_4_fc0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_4_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_4_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_4_task_0_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_4_task_1_out): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (branch_4_task_2_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_4_task_3_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_4_task_4_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_4_task_5_out): Linear(in_features=256, out_features=17, bias=True)\n",
      "  (branch_4_task_6_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_4_task_7_out): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (branch_4_task_8_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_5_fc0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_5_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_5_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_5_task_0_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_5_task_1_out): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (branch_5_task_2_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_5_task_3_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_5_task_4_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_5_task_5_out): Linear(in_features=256, out_features=17, bias=True)\n",
      "  (branch_5_task_6_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_5_task_7_out): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (branch_5_task_8_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_6_fc0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_6_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_6_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_6_task_0_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_6_task_1_out): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (branch_6_task_2_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_6_task_3_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_6_task_4_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_6_task_5_out): Linear(in_features=256, out_features=17, bias=True)\n",
      "  (branch_6_task_6_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_6_task_7_out): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (branch_6_task_8_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_7_fc0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_7_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_7_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_7_task_0_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_7_task_1_out): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (branch_7_task_2_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_7_task_3_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_7_task_4_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_7_task_5_out): Linear(in_features=256, out_features=17, bias=True)\n",
      "  (branch_7_task_6_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_7_task_7_out): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (branch_7_task_8_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_8_fc0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_8_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_8_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (branch_8_task_0_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_8_task_1_out): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (branch_8_task_2_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_8_task_3_out): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (branch_8_task_4_out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (branch_8_task_5_out): Linear(in_features=256, out_features=17, bias=True)\n",
      "  (branch_8_task_6_out): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (branch_8_task_7_out): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (branch_8_task_8_out): Linear(in_features=256, out_features=13, bias=True)\n",
      ")\n",
      "\n",
      "Checkpoint loaded from /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/disentangled_representations/models/2-model-best_valid_loss.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference (batches):   0%|          | 0/220 [00:00<?, ?it/s]/pfs/work7/workspace/scratch/tu_zxmav84-thesis/miniconda3/envs/disentangled_representations/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1711403392949/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "Inference (batches): 100%|██████████| 220/220 [05:37<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to /pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/disentangled_representations/inference/2/2.pkl\n"
     ]
    }
   ],
   "source": [
    "from infer import infer\n",
    "\n",
    "model_id = 2\n",
    "infer(\n",
    "        checkpoint=f'{DATA_PATH}/Models/disentangled_representations/models/{model_id}-model-best_valid_loss.pt',\n",
    "        img_dir=f'{DATA_PATH}/Generated_Images/e4e/00005_snapshot_1200/',\n",
    "        save_dir=f'{DATA_PATH}/Models/disentangled_representations/inference/{model_id}',\n",
    "        batch_size=64,\n",
    "        verbose=True,\n",
    "        N=None\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
