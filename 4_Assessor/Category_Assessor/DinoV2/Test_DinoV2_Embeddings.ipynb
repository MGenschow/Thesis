{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import Compose, RandomResizedCrop, RandomHorizontalFlip, ColorJitter, ToTensor, Normalize\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "from Data_Setup import setup_data_loaders, id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.system() == 'Darwin':\n",
    "    DATA_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Data.nosync\"\n",
    "elif platform.system() == 'Linux':\n",
    "    DATA_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'casual_dresses',\n",
       " 1: 'jersey_dresses',\n",
       " 2: 'evening_dresses',\n",
       " 3: 'knitted_dresses',\n",
       " 4: 'maxi_dresses',\n",
       " 5: 'shift_dresses',\n",
       " 6: 'occasion_dresses',\n",
       " 7: 'denim_dresses'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Dinov2ForImageClassification were not initialized from the model checkpoint at facebook/dinov2-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "model_name = \"facebook/dinov2-base\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name, id2label=id2label, label2id=label2id)\n",
    "model = model.to(device)\n",
    "\n",
    "mean = processor.image_mean\n",
    "std = processor.image_std\n",
    "interpolation = processor.resample\n",
    "\n",
    "train_transform = Compose([\n",
    "    #RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=interpolation),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "test_transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, loss_fn, optimizer, report_interval=10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_total = 0\n",
    "    running_correct = 0\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        inputs, labels = data['image'], data['label']\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % report_interval == report_interval - 1:\n",
    "            print(f'\\t[{i + 1}/{len(train_loader)}] loss: {running_loss / report_interval} accuracy: {np.round((running_correct/running_total)*100, 4)}%')\n",
    "            logging.info(f'\\t[{i + 1}/{len(train_loader)}] loss: {running_loss / report_interval} accuracy: {np.round((running_correct/running_total)*100, 4)}%')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            inputs, labels = data['image'], data['label']\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "    import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def test_model(model, test_loader, device='cuda'):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = {}\n",
    "    class_total = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            inputs, labels = data['image'], data['label']\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            \n",
    "            # Update overall accuracy counts\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update per class accuracy counts\n",
    "            for label, prediction in zip(labels, predicted):\n",
    "                if label.item() not in class_correct:\n",
    "                    class_correct[label.item()] = 0\n",
    "                    class_total[label.item()] = 0\n",
    "                class_correct[label.item()] += (prediction == label).item()\n",
    "                class_total[label.item()] += 1\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = correct / total if total > 0 else 0\n",
    "\n",
    "    # Calculate per class accuracy\n",
    "    class_accuracies = {}\n",
    "    for label in class_correct:\n",
    "        class_accuracies[label] = (class_correct[label] / class_total[label]\n",
    "                                   if class_total[label] > 0 else 0)\n",
    "\n",
    "    return overall_accuracy, class_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "BACKBONE_FROZEN = True\n",
    "\n",
    "if BACKBONE_FROZEN:\n",
    "    for param in model.dinov2.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Loss and optimizers\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Model save paths\n",
    "save_dir = f\"{DATA_PATH}/Models/Assessor/DinoV2/batch_size_{BATCH_SIZE}_LR_{LR}_NUM_EPOCHS_{NUM_EPOCHS}/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "train_loader, test_loader = setup_data_loaders(train_transform, test_transform, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:04<06:59,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[1/100] loss: 1.8247530460357666 accuracy: 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:06<05:09,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[2/100] loss: 1.8165723085403442 accuracy: 43.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:09<04:32,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[3/100] loss: 2.9165256023406982 accuracy: 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:11<04:13,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[4/100] loss: 0.9054660201072693 accuracy: 46.875%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:13<04:02,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[5/100] loss: 1.9569811820983887 accuracy: 47.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:16<03:54,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[6/100] loss: 3.456073760986328 accuracy: 39.5833%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:18<03:49,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[7/100] loss: 1.518676519393921 accuracy: 42.8571%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:21<03:44,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[8/100] loss: 1.5953742265701294 accuracy: 42.1875%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:23<03:40,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[9/100] loss: 2.1794373989105225 accuracy: 40.2778%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:25<03:37,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[10/100] loss: 1.9936000108718872 accuracy: 40.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:28<03:34,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[11/100] loss: 2.3001976013183594 accuracy: 36.3636%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:30<03:31,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[12/100] loss: 4.134510040283203 accuracy: 33.3333%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:32<03:29,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[13/100] loss: 1.417230486869812 accuracy: 34.6154%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:35<03:26,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[14/100] loss: 1.1089272499084473 accuracy: 36.6071%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:37<03:23,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[15/100] loss: 1.8612641096115112 accuracy: 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:40<03:21,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[16/100] loss: 1.8556301593780518 accuracy: 35.9375%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:42<03:18,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[17/100] loss: 1.9915390014648438 accuracy: 35.2941%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:44<03:16,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[18/100] loss: 2.295224666595459 accuracy: 36.1111%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:47<03:14,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[19/100] loss: 1.5759873390197754 accuracy: 36.1842%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:49<03:11,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[20/100] loss: 2.015655517578125 accuracy: 36.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:52<03:09,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[21/100] loss: 1.7931270599365234 accuracy: 36.3095%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:54<03:06,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[22/100] loss: 2.5273492336273193 accuracy: 35.7955%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:56<03:04,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[23/100] loss: 1.5743407011032104 accuracy: 36.9565%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:59<03:02,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[24/100] loss: 1.325131893157959 accuracy: 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:01<02:59,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[25/100] loss: 1.4674713611602783 accuracy: 37.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:04<02:57,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[26/100] loss: 2.13875150680542 accuracy: 36.0577%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:06<02:54,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[27/100] loss: 1.5030945539474487 accuracy: 37.037%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:08<02:52,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[28/100] loss: 0.8544535636901855 accuracy: 37.9464%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:11<02:50,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[29/100] loss: 1.9865882396697998 accuracy: 37.931%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [01:13<02:47,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[30/100] loss: 1.1491241455078125 accuracy: 37.9167%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [01:16<02:45,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[31/100] loss: 3.2845852375030518 accuracy: 37.0968%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [01:18<02:42,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[32/100] loss: 1.079061508178711 accuracy: 37.8906%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [01:20<02:40,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[33/100] loss: 1.0771944522857666 accuracy: 38.2576%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [01:23<02:38,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[34/100] loss: 2.416074275970459 accuracy: 37.8676%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [01:25<02:35,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[35/100] loss: 1.0023466348648071 accuracy: 38.9286%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [01:28<02:33,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[36/100] loss: 1.4212942123413086 accuracy: 39.2361%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [01:30<02:30,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[37/100] loss: 1.2923710346221924 accuracy: 39.527%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [01:32<02:28,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[38/100] loss: 1.9053959846496582 accuracy: 38.8158%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [01:35<02:26,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[39/100] loss: 2.453493595123291 accuracy: 38.7821%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:37<02:23,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[40/100] loss: 1.7455047369003296 accuracy: 39.0625%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:40<02:30,  2.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m train_epoch(model, train_loader, loss_fn, optimizer, report_interval\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Save the model \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msave_dir\u001b[39m}\u001b[39;00m\u001b[39mEpoch_\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mlogits, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     running_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     running_correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39;49m labels)\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://127.0.0.1:4948/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis/4_Assessor/Category_Assessor/Data_Preparation/Test_DinoV2_Embeddings.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m report_interval \u001b[39m==\u001b[39m report_interval \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if logging.root.handlers:\n",
    "    # If there are handlers, clear them\n",
    "    logging.root.handlers = []\n",
    "logging.basicConfig(filename=f'{save_dir}log.log', filemode='w', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "print('Starting Training...')\n",
    "# accuracy = test_model(model, test_loader)\n",
    "# print(f\"Initial accuracy: {np.round(accuracy*100, 4)}%\")\n",
    "# logging.warning(f\"Initial accuracy:  {np.round(accuracy*100, 4)}%\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    logging.info(f\"Epoch {epoch}:\")\n",
    "    train_epoch(model, train_loader, loss_fn, optimizer, report_interval=1)\n",
    "    # Save the model \n",
    "    torch.save(model, f\"{save_dir}Epoch_{epoch}\")\n",
    "\n",
    "    # Evaluate the accuracy after each epoch\n",
    "    accuracy, class_accuracy = test_model(model, test_loader)\n",
    "    print(f\"Validation Accuracy after epoch {epoch}: {np.round(accuracy*100, 2)}%\")\n",
    "    logging.info(f\"Validation Accuracy after epoch {epoch}: {np.round(accuracy*100, 2)}%\")\n",
    "    class_accuracies = {id2label[k]:v for k,v in class_accuracy.items()}\n",
    "    logging.info(dict(sorted(class_accuracies.items(), key=lambda item: item[1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
