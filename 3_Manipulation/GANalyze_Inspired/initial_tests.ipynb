{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.nn.functional import softmax\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.system() == 'Darwin':\n",
    "    DATA_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Thesis\"\n",
    "elif platform.system() == 'Linux':\n",
    "    DATA_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis\"\n",
    "\n",
    "current_wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using devices: DinoV2 device: cuda | SG2 device: cuda | General device: cuda\n"
     ]
    }
   ],
   "source": [
    "os.chdir(f\"{ROOT_PATH}/4_Assessor/Category_Assessor/DinoV2\")\n",
    "from helpers_pipeline import *\n",
    "from helper_DinoV2_Embeddings import *\n",
    "id2label = pickle.load(open(\"id2label_dicts/category_id2label.pkl\", \"rb\"))\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using devices: DinoV2 device: cuda | SG2 device: cuda | General device: cuda\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "dino_device, sg2_device, device = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Models Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products data and latents\n",
    "target_feature = 'category'\n",
    "df, latents = load_latents(target_feature)\n",
    "latents = latents.to(sg2_device)\n",
    "\n",
    "# SG2-Ada Generator\n",
    "G = setup_generator()\n",
    "G = G.to(sg2_device)\n",
    "\n",
    "# DinoV2 Model \n",
    "dino_processor, dino_model = setup_dinov2()\n",
    "dino_model = dino_model.to(dino_device)\n",
    "\n",
    "# Attribute Classifier Model\n",
    "classifier = load_classifier()\n",
    "classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeeze all non-relevant model weights and set to eval mode\n",
    "for param in G.parameters():\n",
    "    param.requires_grad = False\n",
    "G.eval()\n",
    "for param in dino_model.parameters():\n",
    "    param.requires_grad = False\n",
    "dino_model.eval()\n",
    "for param in classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "classifier.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator: cuda:0 | Requires Grad: False\n",
      "DinoV2: cuda:0 | Requires Grad: False\n",
      "Classifier: cuda:0 | Requires Grad: False\n"
     ]
    }
   ],
   "source": [
    "# Print devoce for each model: \n",
    "print(f\"Generator: {next(G.parameters()).device} | Requires Grad: {next(G.parameters()).requires_grad}\")\n",
    "print(f\"DinoV2: {next(dino_model.parameters()).device} | Requires Grad: {next(dino_model.parameters()).requires_grad}\")\n",
    "print(f\"Classifier: {next(classifier.parameters()).device} | Requires Grad: {next(classifier.parameters()).requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check gradient flow outside of Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "fixed_alpha = 0.9\n",
    "fixed_class_idx = 7\n",
    "latent = latents[0]\n",
    "\n",
    "directions = torch.randn([8,16,512], device=latent.device, requires_grad=True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([directions], lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    with io.capture_output() as captured:\n",
    "        real_img = G.synthesis(latent, noise_mode='const')\n",
    "    real_dino_input = dino_processor(real_img)\n",
    "    real_dino_embedding = dino_model(real_dino_input)['pooler_output']\n",
    "    real_scores = classifier(real_dino_embedding)\n",
    "    real_probs = softmax(real_scores, dim = 1).squeeze(0)\n",
    "    real_class_prob  = real_probs[fixed_class_idx]\n",
    "\n",
    "    transformed_latent = latent + fixed_alpha * directions[fixed_class_idx]\n",
    "    with io.capture_output() as captured:\n",
    "        trans_img = G.synthesis(transformed_latent, noise_mode='const')\n",
    "    trans_dino_input = dino_processor(trans_img)\n",
    "    trans_dino_embedding = dino_model(trans_dino_input)['pooler_output']\n",
    "    trans_scores = classifier(trans_dino_embedding)\n",
    "    trans_probs = softmax(trans_scores, dim = 1).squeeze(0)\n",
    "    trans_class_prob  = trans_probs[fixed_class_idx]\n",
    "\n",
    "    loss = criterion((real_class_prob + fixed_alpha), trans_class_prob)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Step {i}: Loss: {loss.item()} | Directions sum: {directions.sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Editor(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, generator, dino_model, dino_processor, classifier, id2label, label2id, ):\n",
    "        super(Editor, self).__init__()\n",
    "\n",
    "        self.generator = generator\n",
    "        self.dino_model = dino_model\n",
    "        self.dino_processor = dino_processor\n",
    "        self.classifier = classifier\n",
    "\n",
    "        self.id2label = id2label\n",
    "        self.label2id = label2id   \n",
    "        self.num_classes = len(self.id2label)\n",
    "        self.directions_dimension = [generator.mapping.num_ws, generator.mapping.w_dim]\n",
    "\n",
    "        self.directions = nn.Parameter(torch.randn(self.num_classes,self.directions_dimension[0], self.directions_dimension[1]), requires_grad=True)\n",
    "        self.alphas = np.arange(0,1,0.1)\n",
    "    \n",
    "    def forward(self, latent, class_idx=None, alpha=None):\n",
    "\n",
    "        if class_idx == None:\n",
    "            class_idx = torch.randint(0, self.num_classes, (1,))\n",
    "        \n",
    "        if alpha == None:\n",
    "            alpha = torch.tensor(np.round(np.random.choice(self.alphas),2))\n",
    "\n",
    "        # Get scores for original image\n",
    "        with io.capture_output() as captured:\n",
    "            real_img = self.generator.synthesis(latent, noise_mode='const')\n",
    "        real_dino_input = self.dino_processor(real_img)\n",
    "        real_dino_embedding = self.dino_model(real_dino_input)['pooler_output']\n",
    "        real_scores = self.classifier(real_dino_embedding)\n",
    "        real_probs = softmax(real_scores, dim=0).squeeze(0)\n",
    "        real_class_prob  = real_probs[class_idx]\n",
    "\n",
    "        # Get scores for transformed image\n",
    "        transformed_latent = latent + alpha * self.directions[class_idx].to(latent.device)\n",
    "        with io.capture_output() as captured:\n",
    "            transformed_img = self.generator.synthesis(transformed_latent, noise_mode='const')\n",
    "        transformed_dino_input = self.dino_processor(transformed_img)\n",
    "        transformed_dino_embedding = self.dino_model(transformed_dino_input)['pooler_output']\n",
    "        transformed_scores = self.classifier(transformed_dino_embedding)\n",
    "        transformed_probs = softmax(transformed_scores, dim=0).squeeze(0)\n",
    "        transformed_class_prob = transformed_probs[class_idx]\n",
    "\n",
    "        return real_class_prob, transformed_class_prob, class_idx, alpha\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Editor(G, dino_model, dino_processor, classifier, id2label, label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on one example only\n",
    "\n",
    "- First latent code in the dataset\n",
    "- Real Label: Day Dress: class_idx = 0\n",
    "- Target Label: Denim Dress: class_idx = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | Loss: 0.01 | Real Class Prob: 1.0 | Transformed Class Prob: 1.0\n",
      "Sum of walking direction: -39.65654754638672 | Alpha: 0.1\n",
      "Step: 1 | Loss: 0.01 | Real Class Prob: 1.0 | Transformed Class Prob: 1.0\n",
      "Sum of walking direction: -39.65654754638672 | Alpha: 0.1\n",
      "Step: 2 | Loss: 0.01 | Real Class Prob: 1.0 | Transformed Class Prob: 1.0\n",
      "Sum of walking direction: -39.65654754638672 | Alpha: 0.1\n",
      "Step: 3 | Loss: 0.01 | Real Class Prob: 1.0 | Transformed Class Prob: 1.0\n",
      "Sum of walking direction: -39.65654754638672 | Alpha: 0.1\n",
      "Step: 4 | Loss: 0.01 | Real Class Prob: 1.0 | Transformed Class Prob: 1.0\n",
      "Sum of walking direction: -39.65654754638672 | Alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "fixed_alpha = 0.1\n",
    "fixed_class_idx = 7\n",
    "\n",
    "model = Editor(G, dino_model, dino_processor, classifier, id2label, label2id) \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5)\n",
    "\n",
    "for i in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward:\n",
    "    real_class_prob, transformed_class_prob, class_idx, alpha = model(latents[0], 7, 0.1)\n",
    "    # Loss:\n",
    "    loss = criterion(transformed_class_prob, (real_class_prob + fixed_alpha))\n",
    "    # Backward:\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print updates: \n",
    "    print(f\"Step: {i} | Loss: {np.round(loss.item(),4)} | Real Class Prob: {real_class_prob.item()} | Transformed Class Prob: {transformed_class_prob.item()}\")\n",
    "    print(f\"Sum of walking direction: {torch.sum(model.directions[class_idx])} | Alpha: {alpha}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `latents` is a tensor with requires_grad=True\n",
    "latent = latents[0]\n",
    "generated_image = model.generator.synthesis(latent, noise_mode='const')\n",
    "# Simulate the operation\n",
    "out = model.gan_output_to_image(generated_image)\n",
    "\n",
    "# Perform a dummy operation and check gradients\n",
    "output = pil_to_tensor.sum()\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradient to latents after image conversion:\", latents.grad)  # This will likely show None or zero\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
