{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "if platform.system() == 'Darwin':\n",
    "    DATA_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/Users/maltegenschow/Documents/Uni/Thesis/Thesis\"\n",
    "elif platform.system() == 'Linux':\n",
    "    DATA_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync\"\n",
    "    ROOT_PATH = \"/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Thesis\"\n",
    "\n",
    "current_wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('disentangled_typicality_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2im(var):\n",
    "    var = var.cpu().detach().transpose(0, 2).transpose(0, 1).numpy()\n",
    "    var = ((var + 1) / 2)\n",
    "    var[var < 0] = 0\n",
    "    var[var > 1] = 1\n",
    "    var = var * 255\n",
    "    return Image.fromarray(var.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_generator():\n",
    "    os.chdir(f\"{ROOT_PATH}/stylegan2-ada-pytorch\")\n",
    "    # Load model architecture\n",
    "    experiment_path = f\"{DATA_PATH}/Models/Stylegan2_Ada/Experiments/00005-stylegan2_ada_images-mirror-auto2-kimg5000-resumeffhq512/\"\n",
    "    model_name = \"network-snapshot-001200.pkl\"\n",
    "    model_path = experiment_path + model_name\n",
    "    with open(model_path, 'rb') as f:\n",
    "        architecture = pickle.load(f)\n",
    "        G = architecture['G_ema']\n",
    "        D = architecture['D']\n",
    "    os.chdir(current_wd)\n",
    "    return G\n",
    "\n",
    "G = setup_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_latent(latent):\n",
    "    img = G.synthesis(latent, force_fp32=True, noise_mode = 'const')\n",
    "    img = tensor2im(img.squeeze(0))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu as device\n"
     ]
    }
   ],
   "source": [
    "os.chdir(f\"{ROOT_PATH}/2_Inversion/PTI/\")\n",
    "from pti_utils import load_pti\n",
    "os.chdir(current_wd)\n",
    "\n",
    "def generate_pti(latent, G_PTI):\n",
    "    gen = G_PTI.synthesis(latent, noise_mode='const', force_fp32=True)\n",
    "    img = tensor2im(gen.squeeze(0))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typicality Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InterFaceGAN Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interpolations(latent_code, start_distance, end_distance, steps, boundaries_base_dir):\n",
    "    linspace = np.linspace(start_distance, end_distance, steps)\n",
    "\n",
    "    # Repeat Latent for num_steps\n",
    "    latent_code = latent_code.repeat(steps, 1, 1)\n",
    "\n",
    "    boundary = np.load(f\"{boundaries_base_dir}boundary_dim.npy\")\n",
    "    boundary = torch.tensor(boundary)\n",
    "    for i in range(steps):\n",
    "        latent_code[i, :, :] = latent_code[i, :, :] + linspace[i] * boundary\n",
    "    \n",
    "    return latent_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example(n, embedding_type = 'disentangled_embeddings_concat', direction = 'more', steps=5, distance=15, sku = None, generator = 'SG2'):\n",
    "\n",
    "    boundaries_base_dir = f\"{DATA_PATH}/Models/InterfaceGAN/Outputs/disentangled_typicality/{embedding_type}/{n}/\"\n",
    "\n",
    "    # Load in training stats\n",
    "    training_stats = pd.read_csv(f\"{boundaries_base_dir}summary_stats.csv\")\n",
    "\n",
    "    # Load in original Latents\n",
    "    latents = torch.load(f\"{DATA_PATH}/Models/e4e/00005_snapshot_1200/inversions/latents_dict.pt\")\n",
    "\n",
    "    # Filter to include only SKU for which PTI exists\n",
    "    pti_skus = list(glob('/pfs/work7/workspace/scratch/tu_zxmav84-thesis/Data.nosync/Models/PTI/experiments/embeddings/zalando_germany/PTI/*'))\n",
    "    pti_skus = [elem.split('/')[-1] for elem in pti_skus]\n",
    "    df = meta[meta.sku.isin(pti_skus)]\n",
    "    global chosen_sku\n",
    "\n",
    "    if generator == 'PTI':\n",
    "        # Sample one latent\n",
    "        sample = df.sample(1)\n",
    "        if sku:\n",
    "            sample = df[df.sku == sku]\n",
    "        else: \n",
    "            sample = df.sample(1)\n",
    "            chosen_sku = sample.sku.item()\n",
    "\n",
    "        device = torch.device('cpu')\n",
    "        G_PTI, latent = load_pti(chosen_sku)\n",
    "\n",
    "        # Freeze and set to eval\n",
    "        G_PTI.eval()\n",
    "        for param in G_PTI.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Send to CPU\n",
    "        G_PTI = G_PTI.to(device)\n",
    "        latent_code = latent.to(device)\n",
    "        latent_code =latent_code.squeeze(0).flatten()\n",
    "\n",
    "    elif generator == 'SG2':\n",
    "        if sku:\n",
    "            sample = df[df.sku == sku]\n",
    "        else: \n",
    "            sample = df.sample(1)\n",
    "            chosen_sku = sample.sku.item()\n",
    "        latent_code = latents[sample.sku.item()].squeeze(0).flatten()\n",
    "\n",
    "    # Generate Interpolations\n",
    "    if direction == 'more': \n",
    "        start_distance, end_distance = 0, distance\n",
    "    elif direction == 'less': \n",
    "        start_distance, end_distance = 0,  -distance\n",
    "\n",
    "    interpolations = get_interpolations(latent_code, start_distance, end_distance, steps, boundaries_base_dir)\n",
    "\n",
    "\n",
    "    global imgs\n",
    "    if generator == 'SG2':\n",
    "        imgs = [generate_from_latent(interpolations[i, :, :].squeeze(0).reshape(1,16,512)) for i in range(steps)]\n",
    "    elif generator == 'PTI':\n",
    "        imgs = [generate_pti(interpolations[i, :, :].squeeze(0).reshape(1,16,512), G_PTI) for i in range(steps)]\n",
    "\n",
    "\n",
    "\n",
    "    # Add real image for comparison of first inversion\n",
    "    real = Image.open(f\"{DATA_PATH}/Zalando_Germany_Dataset/dresses/images/square_images/{chosen_sku}.jpg\")\n",
    "\n",
    "    imgs = [real] + imgs\n",
    "\n",
    "    # Calculate typicality scores of generated images\n",
    "    #scores = [calculate_typicality(img) for img in imgs]\n",
    "    scores = [torch.tensor(0)] + [torch.tensor(0) for _ in range(steps)]\n",
    "\n",
    "    fig, ax = plt.subplots(1, steps+1, figsize=(20, 5))\n",
    "    ax = ax.ravel()\n",
    "    for i in range(steps+1):\n",
    "        ax[i].imshow(imgs[i])\n",
    "        ax[i].axis('off')\n",
    "            \n",
    "        if i == 0: \n",
    "            ax[i].set_title(f'Original')\n",
    "        elif i == 1: \n",
    "            ax[i].set_title(f'Inversion\\nTypicality: {np.round(scores[i].item(), 2)}')\n",
    "        else: \n",
    "            step = np.linspace(start_distance, end_distance, steps)[i-1]\n",
    "            ax[i].set_title(f\"{'+' if step > 0 else ''}{step}\\nTypicality: {np.round(scores[i].item(), 2)}\")\n",
    "\n",
    "    \n",
    "    fig.suptitle(f\"SKU: {sample.sku.item()}\\nDirection: {direction} typical\\nGenerator type: \" + r\"\\textbf{\" + generator + \"}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m, in \u001b[0;36mrun_example\u001b[0;34m(n, embedding_type, direction, steps, distance, sku, generator)\u001b[0m\n\u001b[1;32m     41\u001b[0m     sample \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39msku \u001b[38;5;241m==\u001b[39m sku]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m---> 43\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     chosen_sku \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39msku\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     45\u001b[0m latent_code \u001b[38;5;241m=\u001b[39m latents[sample\u001b[38;5;241m.\u001b[39msku\u001b[38;5;241m.\u001b[39mitem()]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.1/envs/master_thesis/lib/python3.10/site-packages/pandas/core/generic.py:6029\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6027\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 6029\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6030\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   6032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.1/envs/master_thesis/lib/python3.10/site-packages/pandas/core/sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    153\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:944\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "run_example(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
